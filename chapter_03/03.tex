%! TEX root = ./main.tex
\begin{exercise}[]{Model Misspecification in Contextual Bandits}
\end{exercise}
In Proposition 10, we showed that for contextual bandits with a general class $\F$,
 SquareCB attains regret
 \[ \Reg \lesssim \sqrt{AT \EstSq(\F,T,\delta)}.\]

 To do so, we assumed that $f^* \in \F$, where 
 $f^*(x,a) := \EEs{r}{r\sim M^*(\cdot|x,a)}$; that is, we have a well- specified model. 
 In practice, it may be unreasonable to assume that we have $f^* \in \F.$
 Instead, a weaker assumption is that there exists some function $\bar f \in \F$ such that
 \[ \max_{x \in \X, a \in \A} |\bar f(x,a)-f^*(x,a)|\leq \epsilon\]
 for some $\epsilon >0$; that is, the model is $\epsilon$-\textit{misspecified}. In this problem,
 we will generalize the regret bound for SquareCB to handle misspecification. Recall that in the lecture notes, we assumed
 that the regression oracle satisfies
 \[ \sum_{t=1}^T \EEs{(\wh f^t(x^t,\pi^t)-f^*(x^t,\pi^t))^2}{\pi^t \sim p^t}\leq \EstSq(\F,T,\delta).\]
 In the misspecified setting, this is too much to ask for. 
 Instead, we will assume that the oracle satisfies the following guarantee for every sequence:
\[ \sum_{t=1}^T(\wh f^t(x^t,\pi^t)-r^t)^2 -\min_{f\in \F}\sum_{t=1}^T(f(x^t,\pi^t)-r^t)^2\leq \Reg_{\text{Sq}}(\F,T).\]
Whenever $f^* \in \F$, we have $\EstSq(\F,T,\delta)\lesssim \Reg_{\text{Sq}}(\F,T)+ \log(1/\delta)$ with probability at least $1-\delta$.
However, it is possible to keep $\Reg_{\text{Sq}}(\F,T)$ small even when $f^* \notin \F$.
For example, the averaged exponential weights algorithm satisfies this guarantee with 
$\Reg_{\text{Sq}} \lesssim \log |\F|$, regardless of whether $f^* \in \F.$

We will show that for every $\delta > 0$, with an appropriate choice of $\gamma$, SquareCB (that is, the algorithm that chooses $p^t =\textbf{IGW}_\gamma(\wh f^t(x^t,\cdot))$ 
ensures that with probability at least $1-\delta$,
\[ \Reg \lesssim \sqrt{AT (\Reg_{\text{Sq}}(\F,T)+\log(1/\delta))} +\epsilon A^{1/2}T.\]

1.  Show that for any sequence of estimators 
$\wh f^1 ,\ldots,\wh f^t,$ by choosing $p_t = \textbf{IGW}_\gamma(\wh f^t(x^t , \cdot))$, we have that
\[\Reg= \sum_{t=1}^T \EEs{f^*(x^t,\pi^*(x^t))-f^*(x^t,\pi^t)}{\pi^t\sim p^t} \lesssim \frac{AT}{\gamma}+ \gamma \sum_{t=1}^T
\EEs{(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))^2}{\pi^t \sim p^t}+\epsilon T.\]

2. Show that the following inequality holds for every sequence
\[ \sum_{t=1}^T(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))^2\leq \Reg_{\text{Sq}}(\F,T)+2\sum_{t=1}^T(r^t-\bar f(x^t,\pi^t))(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t)).\]
3. Using Freedman’s inequality (Lemma 35), show that with probability at least $1-\delta$,
\[\sum_{t=1}^T \EEs{(\wh f^t (x^t,\pi^t)-\bar f(x^t,\pi^t))^2}{\pi^t \sim p^t} \leq 2\sum_{t=1}^T(\wh f^t (x^t, \pi^t)-\bar f (x^t,\pi^t))^2 + \OO(\log(1/\delta)).\]

4. Using Freedman’s inequality once more, show that with probability at least $1-\delta$;
\[ 2\sum_{t=1}^T (r^t-\bar f(x^t,\pi^t)(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))\leq \frac{1}{4}\sum_{t=1}^T \EEs{(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))^2}{\pi^t \sim p^t}  + \OO(\epsilon^2 T + \log(1/\delta)).\]
Conclude that with probability at least $1-\delta$,
\[ \sum_{t=1}^T \EEs{(\wh f^t(x^t,\pi^t)- \bar f(x^t,\pi^t))^2}{\pi^t \sim p^t} \lesssim \Reg_{\text{Sq}(\F,T)}+ \epsilon^2T+\log(1/\delta).\]

5. Combining the previous results, show that for any $\delta > 0$,
 by choosing $\gamma > 0$ appropriately, we have that with probability at least $1-\delta$,

 \[ \Reg \lesssim \sqrt{AT(\Reg_{\text{Sq}}(\F,T)+\log(1/\delta))} +\epsilon A^{1/2}T.  \]


 \begin{solution}[]
    1. We follow the proof of Proposition 9, and break the "regret" term as follows:
    \begin{align*} \EEs{f^*(x^t,\pi^*)-f^*(x^t,\pi^t)}{\pi^t\sim p^t} &= 
        \underbrace{\EEs{\wh f^t(x^t,\wh \pi^t)-\wh f^t(x^t,\pi^t)}{\pi^t \sim p^t}}_{(I)}
    + \underbrace{\EEs{\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t)}{\pi^t \sim p^t}}_{(II)}
   \\
    &+ \underbrace{\EEs{\bar f(x^t,\pi^t)- f^*(x^t,\pi^t)}{\pi^t \sim p^t}}_{(III)} +
     \underbrace{f^*(x^t,\pi^*) - \wh f^t(x^t,\pi^t)}_{(IV)}
    \end{align*}
    Basically compared to the proof of Proposition 9 we have broken the second term which estimates the error on policy into two terms to account for the gap between the true model and the best model in the class. 
    Therefore we can directly apply the results of proposition 9 for the first term and the fourth term which yield:s
    \begin{align*}
        (I) \qquad \EEs{\wh f^t(x^t,\wh \pi^t)-\wh f^t(x^t,\pi^t)}{\pi^t \sim p^t} &\leq \frac{A-1}{2\gamma}\\
        (IV)\qquad  \quad \qquad f^*(x^t,\pi^*) - \wh f^t(x^t,\pi^t) &\leq \frac{A}{2\gamma}
    \end{align*}
    Now we have that (II) is at most:
    \begin{align*}
        \sqrt{\EEs{\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t)}{\pi^t \sim p^t}} \leq \frac{1}{2\gamma}+\frac{\gamma}{2}\EEs{(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))^2}{\pi^t\sim p^t}
    \end{align*}
    And (III) is at most $\epsilon$. Finally putting all the pieces together we get the statement.

2. We assume that for every sequence and every $f \in \F$ the following holds:
\[ \sum_{t=1}^T(\wh f^t(x^t,\pi^t)-r^t)^2 -\sum_{t=1}^T(f(x^t,\pi^t)-r^t)^2\leq \Reg_{\text{Sq}}(\F,T).\]
so it holds in particular for $f = \bar f$.
Now remark that:
\begin{align*}
 &(\wh f^t(x^t,\pi^t) - r^t)^2 - (\bar f(x^t,\pi^t)-r^t)^2 = \wh f^t(x^t,\pi^t)^2 - \bar f(x^t,\pi^t)^2 -2r^t(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t)) \\
 &= (\wh f^t(x^t,\pi^t) - \bar f(x^t,\pi^t))^2 + 2\bar f(x^t,\pi^t)(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))-2r^t(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t)) \\
&=(\wh f^t(x^t,\pi^t) - \bar f(x^t,\pi^t))^2  -2(r^t - \bar f(x^t,\pi^t))(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t)).
\end{align*}
Thus summing over $t=1,\ldots,T$ and putting the second term on the RHS of the inequality yields the statement.

3. We apply Freedman’s inequality to $X_t = (\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))^2$ with respect to the filtration $\F_t = \sigma(x^1,\pi^1,\ldots,x^t,\pi^t)$.
Because $f \in \F$ take values in $[0,1]$ this imples $X_t \leq R= 4.$ and we have with probability $1-\delta$: 
\[\sum_{t=1}^T \EEs{X_t}{t-1}  \leq \sum_{t=1}^T X_t + 8R\log(2/ \delta). \]
which yields the final statement (because $p^t$ is $\F^{t-1}$-measurable) and where the constant in the $\OO (1/\delta)$ equals $32 \log 2$.
Note that here we use the second inequality of Lemma 35 of the book.

4. Once again we apply Freedman’s inequality this time to 
\[X_t = 2(r^t-\bar f(x^t,\pi^t))(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t)).\]
We remark that $\EEs{X_t}{t-1} = 2\EEs{(f^*(x^t,\pi^t)-\bar f(x^t,\pi^t))(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))}{\pi^t \sim p^t}.$
adding and substracting $\wh f^t$ yield:
\begin{align*}\EEs{X_t}{t-1} &=2\EEs{(f^*(x^t,\pi^t)-\wh f^t(x^t,\pi^t))(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))}{\pi^t \sim p^t}\\ 
&+2\EEs{(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))^2}{\pi^t \sim p^t}
\end{align*}


????? (TO DO)

Finally we obtain that  \[ 2\sum_{t=1}^T (r^t-\bar f(x^t,\pi^t)(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))\leq \frac{1}{4}\sum_{t=1}^T \EEs{(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))^2}{\pi^t \sim p^t}  + \OO(\epsilon^2 T + \log(1/\delta)).\]
Combining question 2 and 3 it holds,
\begin{align*}
\sum_{t=1}^T \EEs{(\wh f^t (x^t,\pi^t)-\bar f(x^t,\pi^t))^2}{\pi^t \sim p^t}  \leq &2 \Reg_{\text{Sq}}(\F,T)+4\sum_{t=1}^T(r^t-\bar f(x^t,\pi^t))(\wh f^t(x^t,\pi^t)-\bar f(x^t,\pi^t))\\
&+\OO(\log(1/\delta))
\end{align*}
Now putting all together rearranging terms we finally have 
\[\sum_{t=1}^T \EEs{(\wh f^t (x^t,\pi^t)-\bar f(x^t,\pi^t))^2}{\pi^t \sim p^t} \lesssim \Reg_{\text{Sq}}(\F,T)+\epsilon^2T+\log(1/\delta)\]




5. We combine the result of question 1 with the result of question 5, this yields for any $\delta > 0$ with probability $1-\delta$:
\[ \Reg \lesssim \frac{AT}{\gamma} + \gamma \left( \Reg_{\text{Sq}}(\F,T) + \log(1/\delta)+ \epsilon^2 T \right) + \epsilon T.\]

Taking $\gamma = \sqrt{\frac{AT}{\Reg_{\text{Sq}(\F,T)}+\log(1/\delta) + \epsilon^2 T}}$  gives the desired bound (at least for $T$ large enough and omitting constants).

\end{solution}
